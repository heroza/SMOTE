{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/SMOTE/blob/main/Skin_Cancer_Diagnosis_using_ADASYN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "ebc70ece-a4e5-4f72-f80e-cd2d3e71ffec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2MJBYq-oiB",
        "outputId": "61e4c31d-30de-45fe-879e-c64c38efe320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 300\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'\n",
        "\n",
        "#Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2), \n",
        "  layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.3, 0.3, fill_mode='reflect', interpolation='bilinear',)\n",
        "])\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_no.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=50, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=50,monitor='val_balanced_acc')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def balanced_acc(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    \n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    return balanced_acc\n",
        "\n",
        "def define_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    # compile model\n",
        "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999):\n",
        "  #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val, df_train, df_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE()\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN()\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE()\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exp"
      ],
      "metadata": {
        "id": "UswA0co2y1wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ],
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(base_model.layers)):\n",
        "    layer = base_model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcn8hQg3J8yP",
        "outputId": "3fcb951e-1661-41a0-9076-832eb4fd3e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_8 (None, 224, 224, 3)\n",
            "1 conv1_pad (None, 230, 230, 3)\n",
            "2 conv1_conv (None, 112, 112, 64)\n",
            "3 conv1_bn (None, 112, 112, 64)\n",
            "4 conv1_relu (None, 112, 112, 64)\n",
            "5 pool1_pad (None, 114, 114, 64)\n",
            "6 pool1_pool (None, 56, 56, 64)\n",
            "7 conv2_block1_1_conv (None, 56, 56, 64)\n",
            "8 conv2_block1_1_bn (None, 56, 56, 64)\n",
            "9 conv2_block1_1_relu (None, 56, 56, 64)\n",
            "10 conv2_block1_2_conv (None, 56, 56, 64)\n",
            "11 conv2_block1_2_bn (None, 56, 56, 64)\n",
            "12 conv2_block1_2_relu (None, 56, 56, 64)\n",
            "13 conv2_block1_0_conv (None, 56, 56, 256)\n",
            "14 conv2_block1_3_conv (None, 56, 56, 256)\n",
            "15 conv2_block1_0_bn (None, 56, 56, 256)\n",
            "16 conv2_block1_3_bn (None, 56, 56, 256)\n",
            "17 conv2_block1_add (None, 56, 56, 256)\n",
            "18 conv2_block1_out (None, 56, 56, 256)\n",
            "19 conv2_block2_1_conv (None, 56, 56, 64)\n",
            "20 conv2_block2_1_bn (None, 56, 56, 64)\n",
            "21 conv2_block2_1_relu (None, 56, 56, 64)\n",
            "22 conv2_block2_2_conv (None, 56, 56, 64)\n",
            "23 conv2_block2_2_bn (None, 56, 56, 64)\n",
            "24 conv2_block2_2_relu (None, 56, 56, 64)\n",
            "25 conv2_block2_3_conv (None, 56, 56, 256)\n",
            "26 conv2_block2_3_bn (None, 56, 56, 256)\n",
            "27 conv2_block2_add (None, 56, 56, 256)\n",
            "28 conv2_block2_out (None, 56, 56, 256)\n",
            "29 conv2_block3_1_conv (None, 56, 56, 64)\n",
            "30 conv2_block3_1_bn (None, 56, 56, 64)\n",
            "31 conv2_block3_1_relu (None, 56, 56, 64)\n",
            "32 conv2_block3_2_conv (None, 56, 56, 64)\n",
            "33 conv2_block3_2_bn (None, 56, 56, 64)\n",
            "34 conv2_block3_2_relu (None, 56, 56, 64)\n",
            "35 conv2_block3_3_conv (None, 56, 56, 256)\n",
            "36 conv2_block3_3_bn (None, 56, 56, 256)\n",
            "37 conv2_block3_add (None, 56, 56, 256)\n",
            "38 conv2_block3_out (None, 56, 56, 256)\n",
            "39 conv3_block1_1_conv (None, 28, 28, 128)\n",
            "40 conv3_block1_1_bn (None, 28, 28, 128)\n",
            "41 conv3_block1_1_relu (None, 28, 28, 128)\n",
            "42 conv3_block1_2_conv (None, 28, 28, 128)\n",
            "43 conv3_block1_2_bn (None, 28, 28, 128)\n",
            "44 conv3_block1_2_relu (None, 28, 28, 128)\n",
            "45 conv3_block1_0_conv (None, 28, 28, 512)\n",
            "46 conv3_block1_3_conv (None, 28, 28, 512)\n",
            "47 conv3_block1_0_bn (None, 28, 28, 512)\n",
            "48 conv3_block1_3_bn (None, 28, 28, 512)\n",
            "49 conv3_block1_add (None, 28, 28, 512)\n",
            "50 conv3_block1_out (None, 28, 28, 512)\n",
            "51 conv3_block2_1_conv (None, 28, 28, 128)\n",
            "52 conv3_block2_1_bn (None, 28, 28, 128)\n",
            "53 conv3_block2_1_relu (None, 28, 28, 128)\n",
            "54 conv3_block2_2_conv (None, 28, 28, 128)\n",
            "55 conv3_block2_2_bn (None, 28, 28, 128)\n",
            "56 conv3_block2_2_relu (None, 28, 28, 128)\n",
            "57 conv3_block2_3_conv (None, 28, 28, 512)\n",
            "58 conv3_block2_3_bn (None, 28, 28, 512)\n",
            "59 conv3_block2_add (None, 28, 28, 512)\n",
            "60 conv3_block2_out (None, 28, 28, 512)\n",
            "61 conv3_block3_1_conv (None, 28, 28, 128)\n",
            "62 conv3_block3_1_bn (None, 28, 28, 128)\n",
            "63 conv3_block3_1_relu (None, 28, 28, 128)\n",
            "64 conv3_block3_2_conv (None, 28, 28, 128)\n",
            "65 conv3_block3_2_bn (None, 28, 28, 128)\n",
            "66 conv3_block3_2_relu (None, 28, 28, 128)\n",
            "67 conv3_block3_3_conv (None, 28, 28, 512)\n",
            "68 conv3_block3_3_bn (None, 28, 28, 512)\n",
            "69 conv3_block3_add (None, 28, 28, 512)\n",
            "70 conv3_block3_out (None, 28, 28, 512)\n",
            "71 conv3_block4_1_conv (None, 28, 28, 128)\n",
            "72 conv3_block4_1_bn (None, 28, 28, 128)\n",
            "73 conv3_block4_1_relu (None, 28, 28, 128)\n",
            "74 conv3_block4_2_conv (None, 28, 28, 128)\n",
            "75 conv3_block4_2_bn (None, 28, 28, 128)\n",
            "76 conv3_block4_2_relu (None, 28, 28, 128)\n",
            "77 conv3_block4_3_conv (None, 28, 28, 512)\n",
            "78 conv3_block4_3_bn (None, 28, 28, 512)\n",
            "79 conv3_block4_add (None, 28, 28, 512)\n",
            "80 conv3_block4_out (None, 28, 28, 512)\n",
            "81 conv4_block1_1_conv (None, 14, 14, 256)\n",
            "82 conv4_block1_1_bn (None, 14, 14, 256)\n",
            "83 conv4_block1_1_relu (None, 14, 14, 256)\n",
            "84 conv4_block1_2_conv (None, 14, 14, 256)\n",
            "85 conv4_block1_2_bn (None, 14, 14, 256)\n",
            "86 conv4_block1_2_relu (None, 14, 14, 256)\n",
            "87 conv4_block1_0_conv (None, 14, 14, 1024)\n",
            "88 conv4_block1_3_conv (None, 14, 14, 1024)\n",
            "89 conv4_block1_0_bn (None, 14, 14, 1024)\n",
            "90 conv4_block1_3_bn (None, 14, 14, 1024)\n",
            "91 conv4_block1_add (None, 14, 14, 1024)\n",
            "92 conv4_block1_out (None, 14, 14, 1024)\n",
            "93 conv4_block2_1_conv (None, 14, 14, 256)\n",
            "94 conv4_block2_1_bn (None, 14, 14, 256)\n",
            "95 conv4_block2_1_relu (None, 14, 14, 256)\n",
            "96 conv4_block2_2_conv (None, 14, 14, 256)\n",
            "97 conv4_block2_2_bn (None, 14, 14, 256)\n",
            "98 conv4_block2_2_relu (None, 14, 14, 256)\n",
            "99 conv4_block2_3_conv (None, 14, 14, 1024)\n",
            "100 conv4_block2_3_bn (None, 14, 14, 1024)\n",
            "101 conv4_block2_add (None, 14, 14, 1024)\n",
            "102 conv4_block2_out (None, 14, 14, 1024)\n",
            "103 conv4_block3_1_conv (None, 14, 14, 256)\n",
            "104 conv4_block3_1_bn (None, 14, 14, 256)\n",
            "105 conv4_block3_1_relu (None, 14, 14, 256)\n",
            "106 conv4_block3_2_conv (None, 14, 14, 256)\n",
            "107 conv4_block3_2_bn (None, 14, 14, 256)\n",
            "108 conv4_block3_2_relu (None, 14, 14, 256)\n",
            "109 conv4_block3_3_conv (None, 14, 14, 1024)\n",
            "110 conv4_block3_3_bn (None, 14, 14, 1024)\n",
            "111 conv4_block3_add (None, 14, 14, 1024)\n",
            "112 conv4_block3_out (None, 14, 14, 1024)\n",
            "113 conv4_block4_1_conv (None, 14, 14, 256)\n",
            "114 conv4_block4_1_bn (None, 14, 14, 256)\n",
            "115 conv4_block4_1_relu (None, 14, 14, 256)\n",
            "116 conv4_block4_2_conv (None, 14, 14, 256)\n",
            "117 conv4_block4_2_bn (None, 14, 14, 256)\n",
            "118 conv4_block4_2_relu (None, 14, 14, 256)\n",
            "119 conv4_block4_3_conv (None, 14, 14, 1024)\n",
            "120 conv4_block4_3_bn (None, 14, 14, 1024)\n",
            "121 conv4_block4_add (None, 14, 14, 1024)\n",
            "122 conv4_block4_out (None, 14, 14, 1024)\n",
            "123 conv4_block5_1_conv (None, 14, 14, 256)\n",
            "124 conv4_block5_1_bn (None, 14, 14, 256)\n",
            "125 conv4_block5_1_relu (None, 14, 14, 256)\n",
            "126 conv4_block5_2_conv (None, 14, 14, 256)\n",
            "127 conv4_block5_2_bn (None, 14, 14, 256)\n",
            "128 conv4_block5_2_relu (None, 14, 14, 256)\n",
            "129 conv4_block5_3_conv (None, 14, 14, 1024)\n",
            "130 conv4_block5_3_bn (None, 14, 14, 1024)\n",
            "131 conv4_block5_add (None, 14, 14, 1024)\n",
            "132 conv4_block5_out (None, 14, 14, 1024)\n",
            "133 conv4_block6_1_conv (None, 14, 14, 256)\n",
            "134 conv4_block6_1_bn (None, 14, 14, 256)\n",
            "135 conv4_block6_1_relu (None, 14, 14, 256)\n",
            "136 conv4_block6_2_conv (None, 14, 14, 256)\n",
            "137 conv4_block6_2_bn (None, 14, 14, 256)\n",
            "138 conv4_block6_2_relu (None, 14, 14, 256)\n",
            "139 conv4_block6_3_conv (None, 14, 14, 1024)\n",
            "140 conv4_block6_3_bn (None, 14, 14, 1024)\n",
            "141 conv4_block6_add (None, 14, 14, 1024)\n",
            "142 conv4_block6_out (None, 14, 14, 1024)\n",
            "143 conv5_block1_1_conv (None, 7, 7, 512)\n",
            "144 conv5_block1_1_bn (None, 7, 7, 512)\n",
            "145 conv5_block1_1_relu (None, 7, 7, 512)\n",
            "146 conv5_block1_2_conv (None, 7, 7, 512)\n",
            "147 conv5_block1_2_bn (None, 7, 7, 512)\n",
            "148 conv5_block1_2_relu (None, 7, 7, 512)\n",
            "149 conv5_block1_0_conv (None, 7, 7, 2048)\n",
            "150 conv5_block1_3_conv (None, 7, 7, 2048)\n",
            "151 conv5_block1_0_bn (None, 7, 7, 2048)\n",
            "152 conv5_block1_3_bn (None, 7, 7, 2048)\n",
            "153 conv5_block1_add (None, 7, 7, 2048)\n",
            "154 conv5_block1_out (None, 7, 7, 2048)\n",
            "155 conv5_block2_1_conv (None, 7, 7, 512)\n",
            "156 conv5_block2_1_bn (None, 7, 7, 512)\n",
            "157 conv5_block2_1_relu (None, 7, 7, 512)\n",
            "158 conv5_block2_2_conv (None, 7, 7, 512)\n",
            "159 conv5_block2_2_bn (None, 7, 7, 512)\n",
            "160 conv5_block2_2_relu (None, 7, 7, 512)\n",
            "161 conv5_block2_3_conv (None, 7, 7, 2048)\n",
            "162 conv5_block2_3_bn (None, 7, 7, 2048)\n",
            "163 conv5_block2_add (None, 7, 7, 2048)\n",
            "164 conv5_block2_out (None, 7, 7, 2048)\n",
            "165 conv5_block3_1_conv (None, 7, 7, 512)\n",
            "166 conv5_block3_1_bn (None, 7, 7, 512)\n",
            "167 conv5_block3_1_relu (None, 7, 7, 512)\n",
            "168 conv5_block3_2_conv (None, 7, 7, 512)\n",
            "169 conv5_block3_2_bn (None, 7, 7, 512)\n",
            "170 conv5_block3_2_relu (None, 7, 7, 512)\n",
            "171 conv5_block3_3_conv (None, 7, 7, 2048)\n",
            "172 conv5_block3_3_bn (None, 7, 7, 2048)\n",
            "173 conv5_block3_add (None, 7, 7, 2048)\n",
            "174 conv5_block3_out (None, 7, 7, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA7Af2Y73FUv",
        "outputId": "f41b2828-ad8d-4cd3-ac77-8a04be113794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 2048)\n",
            "(5321, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krJiAb1m3QNf",
        "outputId": "fc0dfaf9-da03-4d79-c03d-584362e908f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bw4C7Fwwxad"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_cifar10_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QM00erNGU32",
        "outputId": "9a5b6e0d-eb0f-45de-a6bb-23b588f2f22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 224, 224, 3)\n",
            "(5321, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "X_train, y_train, X_val, y_val, df_train, df_val = load_isic2018_dataset(train_under_frac = 0.7)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-rGI2h3JN5s"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xArGWuciBt_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f921fcfd-a197-4d3d-9d34-ab707a349036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14195, 224, 224, 3)\n",
            "(14195, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({1: 2093, 4: 2052, 6: 2042, 3: 2033, 0: 2020, 5: 2011, 2: 1944})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, type=\"adasyn\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8eRZiucdYnP"
      },
      "outputs": [],
      "source": [
        "#USe TF.data\n",
        "#training_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "#validation_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "\n",
        "#autotune = tf.data.AUTOTUNE\n",
        "#train_data_batches = training_data.shuffle(buffer_size=40000).batch(BATCH_SIZE).prefetch(buffer_size=autotune)\n",
        "#valid_data_batches = validation_data.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(buffer_size=autotune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qge6cnxQPnH6"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train.pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,224,224,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAMBgWqIsAAB",
        "outputId": "52b23094-6efb-4a4c-8b60-d31749f216bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 224, 224, 3)\n",
            "(5321, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIygrW81Ln4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56071bd2-5d0a-4448-b12d-76a69e506e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 1.6365 - accuracy: 0.3826 - balanced_acc: 0.3800\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.30707, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 41s 125ms/step - loss: 1.6365 - accuracy: 0.3826 - balanced_acc: 0.3800 - val_loss: 1.3812 - val_accuracy: 0.5233 - val_balanced_acc: 0.3071 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 1.2779 - accuracy: 0.5370 - balanced_acc: 0.5372\n",
            "Epoch 2: val_balanced_acc improved from 0.30707 to 0.32640, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 1.2779 - accuracy: 0.5370 - balanced_acc: 0.5372 - val_loss: 1.2109 - val_accuracy: 0.5596 - val_balanced_acc: 0.3264 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 1.1420 - accuracy: 0.5833 - balanced_acc: 0.5818\n",
            "Epoch 3: val_balanced_acc improved from 0.32640 to 0.35208, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 1.1420 - accuracy: 0.5833 - balanced_acc: 0.5818 - val_loss: 1.0779 - val_accuracy: 0.6166 - val_balanced_acc: 0.3521 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 1.0505 - accuracy: 0.6179 - balanced_acc: 0.6162\n",
            "Epoch 4: val_balanced_acc improved from 0.35208 to 0.36685, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 1.0505 - accuracy: 0.6179 - balanced_acc: 0.6162 - val_loss: 1.0164 - val_accuracy: 0.6321 - val_balanced_acc: 0.3669 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.9886 - accuracy: 0.6382 - balanced_acc: 0.6357\n",
            "Epoch 5: val_balanced_acc did not improve from 0.36685\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.9886 - accuracy: 0.6382 - balanced_acc: 0.6357 - val_loss: 1.0324 - val_accuracy: 0.6166 - val_balanced_acc: 0.3547 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.9463 - accuracy: 0.6578 - balanced_acc: 0.6547\n",
            "Epoch 6: val_balanced_acc did not improve from 0.36685\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.9463 - accuracy: 0.6578 - balanced_acc: 0.6547 - val_loss: 0.9599 - val_accuracy: 0.6269 - val_balanced_acc: 0.3602 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.9138 - accuracy: 0.6608 - balanced_acc: 0.6595\n",
            "Epoch 7: val_balanced_acc improved from 0.36685 to 0.40750, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.9138 - accuracy: 0.6608 - balanced_acc: 0.6595 - val_loss: 0.9372 - val_accuracy: 0.6684 - val_balanced_acc: 0.4075 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.6811 - balanced_acc: 0.6810\n",
            "Epoch 8: val_balanced_acc did not improve from 0.40750\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.8778 - accuracy: 0.6811 - balanced_acc: 0.6810 - val_loss: 0.9025 - val_accuracy: 0.6736 - val_balanced_acc: 0.3997 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.8456 - accuracy: 0.6944 - balanced_acc: 0.6915\n",
            "Epoch 9: val_balanced_acc did not improve from 0.40750\n",
            "221/221 [==============================] - 23s 105ms/step - loss: 0.8456 - accuracy: 0.6944 - balanced_acc: 0.6915 - val_loss: 0.8812 - val_accuracy: 0.6839 - val_balanced_acc: 0.4073 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.8316 - accuracy: 0.6980 - balanced_acc: 0.6959\n",
            "Epoch 10: val_balanced_acc improved from 0.40750 to 0.41055, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 112ms/step - loss: 0.8316 - accuracy: 0.6980 - balanced_acc: 0.6959 - val_loss: 0.8803 - val_accuracy: 0.7047 - val_balanced_acc: 0.4106 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.8035 - accuracy: 0.7074 - balanced_acc: 0.7067\n",
            "Epoch 11: val_balanced_acc improved from 0.41055 to 0.41776, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 26s 115ms/step - loss: 0.8035 - accuracy: 0.7074 - balanced_acc: 0.7067 - val_loss: 0.8560 - val_accuracy: 0.7047 - val_balanced_acc: 0.4178 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.7176 - balanced_acc: 0.7162\n",
            "Epoch 12: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.7845 - accuracy: 0.7176 - balanced_acc: 0.7162 - val_loss: 0.8568 - val_accuracy: 0.7098 - val_balanced_acc: 0.4158 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.7745 - accuracy: 0.7229 - balanced_acc: 0.7215\n",
            "Epoch 13: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.7745 - accuracy: 0.7229 - balanced_acc: 0.7215 - val_loss: 0.8796 - val_accuracy: 0.6736 - val_balanced_acc: 0.4038 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.7529 - accuracy: 0.7261 - balanced_acc: 0.7236\n",
            "Epoch 14: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.7529 - accuracy: 0.7261 - balanced_acc: 0.7236 - val_loss: 0.8321 - val_accuracy: 0.7047 - val_balanced_acc: 0.4091 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.7355 - accuracy: 0.7313 - balanced_acc: 0.7306\n",
            "Epoch 15: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.7355 - accuracy: 0.7313 - balanced_acc: 0.7306 - val_loss: 0.8489 - val_accuracy: 0.6943 - val_balanced_acc: 0.4073 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.7393 - balanced_acc: 0.7372\n",
            "Epoch 16: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.7217 - accuracy: 0.7393 - balanced_acc: 0.7372 - val_loss: 0.8438 - val_accuracy: 0.6943 - val_balanced_acc: 0.4073 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.7430 - balanced_acc: 0.7414\n",
            "Epoch 17: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.7059 - accuracy: 0.7430 - balanced_acc: 0.7414 - val_loss: 0.7980 - val_accuracy: 0.7047 - val_balanced_acc: 0.4090 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.7520 - balanced_acc: 0.7519\n",
            "Epoch 18: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.6953 - accuracy: 0.7520 - balanced_acc: 0.7519 - val_loss: 0.8355 - val_accuracy: 0.6943 - val_balanced_acc: 0.4100 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.7523 - balanced_acc: 0.7548\n",
            "Epoch 19: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.6811 - accuracy: 0.7523 - balanced_acc: 0.7548 - val_loss: 0.8516 - val_accuracy: 0.6788 - val_balanced_acc: 0.4094 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.7503 - balanced_acc: 0.7496\n",
            "Epoch 20: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.6807 - accuracy: 0.7503 - balanced_acc: 0.7496 - val_loss: 0.8394 - val_accuracy: 0.6736 - val_balanced_acc: 0.4053 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.7629 - balanced_acc: 0.7609\n",
            "Epoch 21: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.6599 - accuracy: 0.7629 - balanced_acc: 0.7609 - val_loss: 0.8086 - val_accuracy: 0.6995 - val_balanced_acc: 0.4150 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.7648 - balanced_acc: 0.7640\n",
            "Epoch 22: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.6527 - accuracy: 0.7648 - balanced_acc: 0.7640 - val_loss: 0.8165 - val_accuracy: 0.7047 - val_balanced_acc: 0.4175 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.7675 - balanced_acc: 0.7640\n",
            "Epoch 23: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.6425 - accuracy: 0.7675 - balanced_acc: 0.7640 - val_loss: 0.8135 - val_accuracy: 0.6839 - val_balanced_acc: 0.4124 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.7713 - balanced_acc: 0.7693\n",
            "Epoch 24: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 105ms/step - loss: 0.6388 - accuracy: 0.7713 - balanced_acc: 0.7693 - val_loss: 0.7782 - val_accuracy: 0.7150 - val_balanced_acc: 0.4165 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.7762 - balanced_acc: 0.7728\n",
            "Epoch 25: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.6262 - accuracy: 0.7762 - balanced_acc: 0.7728 - val_loss: 0.7539 - val_accuracy: 0.7098 - val_balanced_acc: 0.4114 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.7798 - balanced_acc: 0.7784\n",
            "Epoch 26: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.6140 - accuracy: 0.7798 - balanced_acc: 0.7784 - val_loss: 0.7838 - val_accuracy: 0.6995 - val_balanced_acc: 0.4081 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.6089 - accuracy: 0.7810 - balanced_acc: 0.7788\n",
            "Epoch 27: val_balanced_acc did not improve from 0.41776\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.6089 - accuracy: 0.7810 - balanced_acc: 0.7788 - val_loss: 0.8258 - val_accuracy: 0.6788 - val_balanced_acc: 0.4046 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.7936 - balanced_acc: 0.7931\n",
            "Epoch 28: val_balanced_acc improved from 0.41776 to 0.41999, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.5936 - accuracy: 0.7936 - balanced_acc: 0.7931 - val_loss: 0.7751 - val_accuracy: 0.7202 - val_balanced_acc: 0.4200 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7922 - balanced_acc: 0.7892\n",
            "Epoch 29: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5853 - accuracy: 0.7922 - balanced_acc: 0.7892 - val_loss: 0.7957 - val_accuracy: 0.6788 - val_balanced_acc: 0.4088 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7912 - balanced_acc: 0.7907\n",
            "Epoch 30: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.5838 - accuracy: 0.7912 - balanced_acc: 0.7907 - val_loss: 0.7894 - val_accuracy: 0.6736 - val_balanced_acc: 0.4038 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.7925 - balanced_acc: 0.7924\n",
            "Epoch 31: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5751 - accuracy: 0.7925 - balanced_acc: 0.7924 - val_loss: 0.7620 - val_accuracy: 0.7047 - val_balanced_acc: 0.4132 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7999 - balanced_acc: 0.7985\n",
            "Epoch 32: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5662 - accuracy: 0.7999 - balanced_acc: 0.7985 - val_loss: 0.7878 - val_accuracy: 0.6839 - val_balanced_acc: 0.4140 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.7992 - balanced_acc: 0.7970\n",
            "Epoch 33: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5619 - accuracy: 0.7992 - balanced_acc: 0.7970 - val_loss: 0.7743 - val_accuracy: 0.6943 - val_balanced_acc: 0.4073 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7984 - balanced_acc: 0.7967\n",
            "Epoch 34: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5601 - accuracy: 0.7984 - balanced_acc: 0.7967 - val_loss: 0.8022 - val_accuracy: 0.6736 - val_balanced_acc: 0.4122 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.8050 - balanced_acc: 0.8049\n",
            "Epoch 35: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5438 - accuracy: 0.8050 - balanced_acc: 0.8049 - val_loss: 0.7676 - val_accuracy: 0.6839 - val_balanced_acc: 0.4056 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8057 - balanced_acc: 0.8046\n",
            "Epoch 36: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5425 - accuracy: 0.8057 - balanced_acc: 0.8046 - val_loss: 0.7792 - val_accuracy: 0.6684 - val_balanced_acc: 0.4029 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5324 - accuracy: 0.8064 - balanced_acc: 0.8044\n",
            "Epoch 37: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5324 - accuracy: 0.8064 - balanced_acc: 0.8044 - val_loss: 0.7671 - val_accuracy: 0.6839 - val_balanced_acc: 0.4114 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.8114 - balanced_acc: 0.8102\n",
            "Epoch 38: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5305 - accuracy: 0.8114 - balanced_acc: 0.8102 - val_loss: 0.7330 - val_accuracy: 0.7098 - val_balanced_acc: 0.4157 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.8147 - balanced_acc: 0.8149\n",
            "Epoch 39: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5246 - accuracy: 0.8147 - balanced_acc: 0.8149 - val_loss: 0.7492 - val_accuracy: 0.6891 - val_balanced_acc: 0.4122 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.8174 - balanced_acc: 0.8177\n",
            "Epoch 40: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5180 - accuracy: 0.8174 - balanced_acc: 0.8177 - val_loss: 0.7261 - val_accuracy: 0.7150 - val_balanced_acc: 0.4175 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8254 - balanced_acc: 0.8229\n",
            "Epoch 41: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5043 - accuracy: 0.8254 - balanced_acc: 0.8229 - val_loss: 0.7376 - val_accuracy: 0.6943 - val_balanced_acc: 0.4089 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.8249 - balanced_acc: 0.8230\n",
            "Epoch 42: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.5038 - accuracy: 0.8249 - balanced_acc: 0.8230 - val_loss: 0.7703 - val_accuracy: 0.6788 - val_balanced_acc: 0.4078 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.8260 - balanced_acc: 0.8263\n",
            "Epoch 43: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4985 - accuracy: 0.8260 - balanced_acc: 0.8263 - val_loss: 0.7476 - val_accuracy: 0.6995 - val_balanced_acc: 0.4124 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8258 - balanced_acc: 0.8248\n",
            "Epoch 44: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4977 - accuracy: 0.8258 - balanced_acc: 0.8248 - val_loss: 0.7902 - val_accuracy: 0.6684 - val_balanced_acc: 0.4038 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.8352 - balanced_acc: 0.8344\n",
            "Epoch 45: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4828 - accuracy: 0.8352 - balanced_acc: 0.8344 - val_loss: 0.7554 - val_accuracy: 0.6788 - val_balanced_acc: 0.4063 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.8273 - balanced_acc: 0.8264\n",
            "Epoch 46: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4917 - accuracy: 0.8273 - balanced_acc: 0.8264 - val_loss: 0.7567 - val_accuracy: 0.6891 - val_balanced_acc: 0.4134 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8358 - balanced_acc: 0.8335\n",
            "Epoch 47: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4743 - accuracy: 0.8358 - balanced_acc: 0.8335 - val_loss: 0.7308 - val_accuracy: 0.6943 - val_balanced_acc: 0.4103 - lr: 0.0010\n",
            "Epoch 48/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.8356 - balanced_acc: 0.8368\n",
            "Epoch 48: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4760 - accuracy: 0.8356 - balanced_acc: 0.8368 - val_loss: 0.7354 - val_accuracy: 0.6891 - val_balanced_acc: 0.4122 - lr: 0.0010\n",
            "Epoch 49/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.8362 - balanced_acc: 0.8324\n",
            "Epoch 49: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4672 - accuracy: 0.8362 - balanced_acc: 0.8324 - val_loss: 0.7511 - val_accuracy: 0.6736 - val_balanced_acc: 0.4069 - lr: 0.0010\n",
            "Epoch 50/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8384 - balanced_acc: 0.8369\n",
            "Epoch 50: val_balanced_acc did not improve from 0.41999\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4674 - accuracy: 0.8384 - balanced_acc: 0.8369 - val_loss: 0.7681 - val_accuracy: 0.6788 - val_balanced_acc: 0.4104 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.8375 - balanced_acc: 0.8352\n",
            "Epoch 51: val_balanced_acc improved from 0.41999 to 0.42515, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.4618 - accuracy: 0.8375 - balanced_acc: 0.8352 - val_loss: 0.7294 - val_accuracy: 0.6943 - val_balanced_acc: 0.4252 - lr: 0.0010\n",
            "Epoch 52/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8384 - balanced_acc: 0.8377\n",
            "Epoch 52: val_balanced_acc improved from 0.42515 to 0.42664, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.4573 - accuracy: 0.8384 - balanced_acc: 0.8377 - val_loss: 0.7404 - val_accuracy: 0.6995 - val_balanced_acc: 0.4266 - lr: 0.0010\n",
            "Epoch 53/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.8454 - balanced_acc: 0.8431\n",
            "Epoch 53: val_balanced_acc did not improve from 0.42664\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.4469 - accuracy: 0.8454 - balanced_acc: 0.8431 - val_loss: 0.7567 - val_accuracy: 0.6788 - val_balanced_acc: 0.4027 - lr: 0.0010\n",
            "Epoch 54/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.8483 - balanced_acc: 0.8476\n",
            "Epoch 54: val_balanced_acc did not improve from 0.42664\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4442 - accuracy: 0.8483 - balanced_acc: 0.8476 - val_loss: 0.7574 - val_accuracy: 0.6839 - val_balanced_acc: 0.4107 - lr: 0.0010\n",
            "Epoch 55/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8495 - balanced_acc: 0.8463\n",
            "Epoch 55: val_balanced_acc did not improve from 0.42664\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.4436 - accuracy: 0.8495 - balanced_acc: 0.8463 - val_loss: 0.7540 - val_accuracy: 0.6736 - val_balanced_acc: 0.4048 - lr: 0.0010\n",
            "Epoch 56/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.8484 - balanced_acc: 0.8458\n",
            "Epoch 56: val_balanced_acc did not improve from 0.42664\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.4369 - accuracy: 0.8484 - balanced_acc: 0.8458 - val_loss: 0.7147 - val_accuracy: 0.7098 - val_balanced_acc: 0.4216 - lr: 0.0010\n",
            "Epoch 57/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8500 - balanced_acc: 0.8487\n",
            "Epoch 57: val_balanced_acc did not improve from 0.42664\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.4326 - accuracy: 0.8500 - balanced_acc: 0.8487 - val_loss: 0.7334 - val_accuracy: 0.6891 - val_balanced_acc: 0.4053 - lr: 0.0010\n",
            "Epoch 58/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.8521 - balanced_acc: 0.8522\n",
            "Epoch 58: val_balanced_acc improved from 0.42664 to 0.42942, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 112ms/step - loss: 0.4271 - accuracy: 0.8521 - balanced_acc: 0.8522 - val_loss: 0.7454 - val_accuracy: 0.6943 - val_balanced_acc: 0.4294 - lr: 0.0010\n",
            "Epoch 59/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.8575 - balanced_acc: 0.8559\n",
            "Epoch 59: val_balanced_acc did not improve from 0.42942\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.4219 - accuracy: 0.8575 - balanced_acc: 0.8559 - val_loss: 0.6981 - val_accuracy: 0.7150 - val_balanced_acc: 0.4240 - lr: 0.0010\n",
            "Epoch 60/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8558 - balanced_acc: 0.8523\n",
            "Epoch 60: val_balanced_acc did not improve from 0.42942\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4190 - accuracy: 0.8558 - balanced_acc: 0.8523 - val_loss: 0.7075 - val_accuracy: 0.6995 - val_balanced_acc: 0.4132 - lr: 0.0010\n",
            "Epoch 61/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8586 - balanced_acc: 0.8568\n",
            "Epoch 61: val_balanced_acc did not improve from 0.42942\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4230 - accuracy: 0.8586 - balanced_acc: 0.8568 - val_loss: 0.7500 - val_accuracy: 0.6839 - val_balanced_acc: 0.4131 - lr: 0.0010\n",
            "Epoch 62/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4065 - accuracy: 0.8618 - balanced_acc: 0.8616\n",
            "Epoch 62: val_balanced_acc did not improve from 0.42942\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4065 - accuracy: 0.8618 - balanced_acc: 0.8616 - val_loss: 0.7138 - val_accuracy: 0.6995 - val_balanced_acc: 0.4241 - lr: 0.0010\n",
            "Epoch 63/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.8594 - balanced_acc: 0.8569\n",
            "Epoch 63: val_balanced_acc improved from 0.42942 to 0.43110, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 112ms/step - loss: 0.4114 - accuracy: 0.8594 - balanced_acc: 0.8569 - val_loss: 0.7250 - val_accuracy: 0.7047 - val_balanced_acc: 0.4311 - lr: 0.0010\n",
            "Epoch 64/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8613 - balanced_acc: 0.8603\n",
            "Epoch 64: val_balanced_acc did not improve from 0.43110\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.4094 - accuracy: 0.8613 - balanced_acc: 0.8603 - val_loss: 0.7071 - val_accuracy: 0.7098 - val_balanced_acc: 0.4248 - lr: 0.0010\n",
            "Epoch 65/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8642 - balanced_acc: 0.8638\n",
            "Epoch 65: val_balanced_acc improved from 0.43110 to 0.45936, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.4048 - accuracy: 0.8642 - balanced_acc: 0.8638 - val_loss: 0.7096 - val_accuracy: 0.7150 - val_balanced_acc: 0.4594 - lr: 0.0010\n",
            "Epoch 66/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8652 - balanced_acc: 0.8638\n",
            "Epoch 66: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3946 - accuracy: 0.8652 - balanced_acc: 0.8638 - val_loss: 0.7291 - val_accuracy: 0.6943 - val_balanced_acc: 0.4539 - lr: 0.0010\n",
            "Epoch 67/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8638 - balanced_acc: 0.8638\n",
            "Epoch 67: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3930 - accuracy: 0.8638 - balanced_acc: 0.8638 - val_loss: 0.7212 - val_accuracy: 0.6995 - val_balanced_acc: 0.4284 - lr: 0.0010\n",
            "Epoch 68/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8696 - balanced_acc: 0.8684\n",
            "Epoch 68: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3941 - accuracy: 0.8696 - balanced_acc: 0.8684 - val_loss: 0.7008 - val_accuracy: 0.7047 - val_balanced_acc: 0.4498 - lr: 0.0010\n",
            "Epoch 69/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8722 - balanced_acc: 0.8711\n",
            "Epoch 69: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.3826 - accuracy: 0.8722 - balanced_acc: 0.8711 - val_loss: 0.6719 - val_accuracy: 0.7358 - val_balanced_acc: 0.4318 - lr: 0.0010\n",
            "Epoch 70/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8677 - balanced_acc: 0.8675\n",
            "Epoch 70: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3922 - accuracy: 0.8677 - balanced_acc: 0.8675 - val_loss: 0.7294 - val_accuracy: 0.6995 - val_balanced_acc: 0.4320 - lr: 0.0010\n",
            "Epoch 71/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8709 - balanced_acc: 0.8706\n",
            "Epoch 71: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3820 - accuracy: 0.8709 - balanced_acc: 0.8706 - val_loss: 0.6954 - val_accuracy: 0.7098 - val_balanced_acc: 0.4215 - lr: 0.0010\n",
            "Epoch 72/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8723 - balanced_acc: 0.8716\n",
            "Epoch 72: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.3816 - accuracy: 0.8723 - balanced_acc: 0.8716 - val_loss: 0.7055 - val_accuracy: 0.7150 - val_balanced_acc: 0.4320 - lr: 0.0010\n",
            "Epoch 73/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8728 - balanced_acc: 0.8721\n",
            "Epoch 73: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3746 - accuracy: 0.8728 - balanced_acc: 0.8721 - val_loss: 0.6921 - val_accuracy: 0.7098 - val_balanced_acc: 0.4501 - lr: 0.0010\n",
            "Epoch 74/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8744 - balanced_acc: 0.8724\n",
            "Epoch 74: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.3743 - accuracy: 0.8744 - balanced_acc: 0.8724 - val_loss: 0.7250 - val_accuracy: 0.7098 - val_balanced_acc: 0.4380 - lr: 0.0010\n",
            "Epoch 75/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8783 - balanced_acc: 0.8780\n",
            "Epoch 75: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3673 - accuracy: 0.8783 - balanced_acc: 0.8780 - val_loss: 0.7129 - val_accuracy: 0.7047 - val_balanced_acc: 0.4276 - lr: 0.0010\n",
            "Epoch 76/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8783 - balanced_acc: 0.8778\n",
            "Epoch 76: val_balanced_acc did not improve from 0.45936\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3645 - accuracy: 0.8783 - balanced_acc: 0.8778 - val_loss: 0.7372 - val_accuracy: 0.6995 - val_balanced_acc: 0.4320 - lr: 0.0010\n",
            "Epoch 77/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8822 - balanced_acc: 0.8782\n",
            "Epoch 77: val_balanced_acc improved from 0.45936 to 0.46829, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 112ms/step - loss: 0.3583 - accuracy: 0.8822 - balanced_acc: 0.8782 - val_loss: 0.7074 - val_accuracy: 0.7254 - val_balanced_acc: 0.4683 - lr: 0.0010\n",
            "Epoch 78/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.8808 - balanced_acc: 0.8781\n",
            "Epoch 78: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3600 - accuracy: 0.8808 - balanced_acc: 0.8781 - val_loss: 0.6632 - val_accuracy: 0.7306 - val_balanced_acc: 0.4564 - lr: 0.0010\n",
            "Epoch 79/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8819 - balanced_acc: 0.8805\n",
            "Epoch 79: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3571 - accuracy: 0.8819 - balanced_acc: 0.8805 - val_loss: 0.7235 - val_accuracy: 0.6995 - val_balanced_acc: 0.4225 - lr: 0.0010\n",
            "Epoch 80/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8850 - balanced_acc: 0.8843\n",
            "Epoch 80: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3517 - accuracy: 0.8850 - balanced_acc: 0.8843 - val_loss: 0.6976 - val_accuracy: 0.7254 - val_balanced_acc: 0.4611 - lr: 0.0010\n",
            "Epoch 81/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8813 - balanced_acc: 0.8807\n",
            "Epoch 81: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3511 - accuracy: 0.8813 - balanced_acc: 0.8807 - val_loss: 0.7250 - val_accuracy: 0.7047 - val_balanced_acc: 0.4601 - lr: 0.0010\n",
            "Epoch 82/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8866 - balanced_acc: 0.8863\n",
            "Epoch 82: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3496 - accuracy: 0.8866 - balanced_acc: 0.8863 - val_loss: 0.7205 - val_accuracy: 0.7098 - val_balanced_acc: 0.4381 - lr: 0.0010\n",
            "Epoch 83/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.8898 - balanced_acc: 0.8881\n",
            "Epoch 83: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3374 - accuracy: 0.8898 - balanced_acc: 0.8881 - val_loss: 0.7210 - val_accuracy: 0.6995 - val_balanced_acc: 0.4517 - lr: 0.0010\n",
            "Epoch 84/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 0.8802 - balanced_acc: 0.8804\n",
            "Epoch 84: val_balanced_acc did not improve from 0.46829\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3472 - accuracy: 0.8802 - balanced_acc: 0.8804 - val_loss: 0.6896 - val_accuracy: 0.7254 - val_balanced_acc: 0.4611 - lr: 0.0010\n",
            "Epoch 85/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.8917 - balanced_acc: 0.8898\n",
            "Epoch 85: val_balanced_acc improved from 0.46829 to 0.46887, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.3341 - accuracy: 0.8917 - balanced_acc: 0.8898 - val_loss: 0.6692 - val_accuracy: 0.7409 - val_balanced_acc: 0.4689 - lr: 0.0010\n",
            "Epoch 86/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8887 - balanced_acc: 0.8864\n",
            "Epoch 86: val_balanced_acc did not improve from 0.46887\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3345 - accuracy: 0.8887 - balanced_acc: 0.8864 - val_loss: 0.6983 - val_accuracy: 0.7098 - val_balanced_acc: 0.4633 - lr: 0.0010\n",
            "Epoch 87/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.8929 - balanced_acc: 0.8943\n",
            "Epoch 87: val_balanced_acc did not improve from 0.46887\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3273 - accuracy: 0.8929 - balanced_acc: 0.8943 - val_loss: 0.6723 - val_accuracy: 0.7409 - val_balanced_acc: 0.4644 - lr: 0.0010\n",
            "Epoch 88/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8918 - balanced_acc: 0.8897\n",
            "Epoch 88: val_balanced_acc did not improve from 0.46887\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3272 - accuracy: 0.8918 - balanced_acc: 0.8897 - val_loss: 0.7081 - val_accuracy: 0.7150 - val_balanced_acc: 0.4684 - lr: 0.0010\n",
            "Epoch 89/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.8933 - balanced_acc: 0.8908\n",
            "Epoch 89: val_balanced_acc did not improve from 0.46887\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3283 - accuracy: 0.8933 - balanced_acc: 0.8908 - val_loss: 0.6916 - val_accuracy: 0.7358 - val_balanced_acc: 0.4626 - lr: 0.0010\n",
            "Epoch 90/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8913 - balanced_acc: 0.8914\n",
            "Epoch 90: val_balanced_acc did not improve from 0.46887\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.3290 - accuracy: 0.8913 - balanced_acc: 0.8914 - val_loss: 0.6914 - val_accuracy: 0.7254 - val_balanced_acc: 0.4658 - lr: 0.0010\n",
            "Epoch 91/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8960 - balanced_acc: 0.8943\n",
            "Epoch 91: val_balanced_acc did not improve from 0.46887\n",
            "221/221 [==============================] - 24s 107ms/step - loss: 0.3207 - accuracy: 0.8960 - balanced_acc: 0.8943 - val_loss: 0.6857 - val_accuracy: 0.7358 - val_balanced_acc: 0.4678 - lr: 0.0010\n",
            "Epoch 92/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8939 - balanced_acc: 0.8930\n",
            "Epoch 92: val_balanced_acc improved from 0.46887 to 0.47365, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.3232 - accuracy: 0.8939 - balanced_acc: 0.8930 - val_loss: 0.6983 - val_accuracy: 0.7306 - val_balanced_acc: 0.4736 - lr: 0.0010\n",
            "Epoch 93/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.8979 - balanced_acc: 0.8965\n",
            "Epoch 93: val_balanced_acc did not improve from 0.47365\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3120 - accuracy: 0.8979 - balanced_acc: 0.8965 - val_loss: 0.7162 - val_accuracy: 0.7098 - val_balanced_acc: 0.4624 - lr: 0.0010\n",
            "Epoch 94/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.8949 - balanced_acc: 0.8929\n",
            "Epoch 94: val_balanced_acc did not improve from 0.47365\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3164 - accuracy: 0.8949 - balanced_acc: 0.8929 - val_loss: 0.7047 - val_accuracy: 0.7202 - val_balanced_acc: 0.4726 - lr: 0.0010\n",
            "Epoch 95/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8968 - balanced_acc: 0.8970\n",
            "Epoch 95: val_balanced_acc improved from 0.47365 to 0.47421, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 112ms/step - loss: 0.3123 - accuracy: 0.8968 - balanced_acc: 0.8970 - val_loss: 0.6570 - val_accuracy: 0.7461 - val_balanced_acc: 0.4742 - lr: 0.0010\n",
            "Epoch 96/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.9009 - balanced_acc: 0.9010\n",
            "Epoch 96: val_balanced_acc did not improve from 0.47421\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3032 - accuracy: 0.9009 - balanced_acc: 0.9010 - val_loss: 0.6709 - val_accuracy: 0.7358 - val_balanced_acc: 0.4716 - lr: 0.0010\n",
            "Epoch 97/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.9008 - balanced_acc: 0.9003\n",
            "Epoch 97: val_balanced_acc improved from 0.47421 to 0.47509, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 113ms/step - loss: 0.3062 - accuracy: 0.9008 - balanced_acc: 0.9003 - val_loss: 0.6824 - val_accuracy: 0.7358 - val_balanced_acc: 0.4751 - lr: 0.0010\n",
            "Epoch 98/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.8991 - balanced_acc: 0.8989\n",
            "Epoch 98: val_balanced_acc did not improve from 0.47509\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3073 - accuracy: 0.8991 - balanced_acc: 0.8989 - val_loss: 0.6831 - val_accuracy: 0.7306 - val_balanced_acc: 0.4709 - lr: 0.0010\n",
            "Epoch 99/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.8987 - balanced_acc: 0.8976\n",
            "Epoch 99: val_balanced_acc did not improve from 0.47509\n",
            "221/221 [==============================] - 23s 106ms/step - loss: 0.3049 - accuracy: 0.8987 - balanced_acc: 0.8976 - val_loss: 0.6678 - val_accuracy: 0.7409 - val_balanced_acc: 0.4697 - lr: 0.0010\n",
            "Epoch 100/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.9080 - balanced_acc: 0.9090\n",
            "Epoch 100: val_balanced_acc improved from 0.47509 to 0.47641, saving model to /content/drive/MyDrive/PHD/Model/best_model_no.h5\n",
            "221/221 [==============================] - 25s 112ms/step - loss: 0.2958 - accuracy: 0.9080 - balanced_acc: 0.9090 - val_loss: 0.7166 - val_accuracy: 0.7202 - val_balanced_acc: 0.4764 - lr: 0.0010\n",
            "Epoch 101/300\n",
            "221/221 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.9014 - balanced_acc: 0.9007\n",
            "Epoch 101: val_balanced_acc did not improve from 0.47641\n",
            "221/221 [==============================] - 24s 106ms/step - loss: 0.3037 - accuracy: 0.9014 - balanced_acc: 0.9007 - val_loss: 0.6962 - val_accuracy: 0.7306 - val_balanced_acc: 0.4736 - lr: 0.0010\n",
            "Epoch 102/300\n",
            " 55/221 [======>.......................] - ETA: 17s - loss: 0.2909 - accuracy: 0.9037 - balanced_acc: 0.8982"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = define_base_model('resnet50')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXnW3lmCgln3"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwLiXUSG0IZ"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "#hst = model.fit(train_data_batches,\n",
        "#                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "#                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS3ewyxO_anU"
      },
      "outputs": [],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62454d54-b340-470f-9d47-ea58e7b1aa87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.9144769284959493\n",
            "balanced accuracy on training 0.9137750258261318\n",
            "accuracy on validation 0.7202072538860104\n",
            "balanced accuracy on validation 0.7327665656062868\n",
            "Score on val data:  (0.5462996433391171, 0.7327665656062868, 0.5951072111551692, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Oversampling on feature map level"
      ],
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 143"
      ],
      "metadata": {
        "id": "PtgmvyhCndpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(best_model.layers)):\n",
        "  layer = best_model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ],
      "metadata": {
        "id": "Lm05Zet_B5am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "i = 143\n",
        "model = Model(inputs=best_model.inputs, outputs=best_model.layers[i-1].output)"
      ],
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model.predict(X_train)\n",
        "X_val_fm = model.predict(X_val)"
      ],
      "metadata": {
        "id": "ZVHYG9Rwm28i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_fm.shape"
      ],
      "metadata": {
        "id": "VNozN8-wDUNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data(X_train_fm, y_train, True, 5, 14, 14, 1024)\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "id": "19hK7aQNeAQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Model(inputs=best_model.layers[i-1].output, outputs=best_model.layers[len(best_model.layers)-1].output)"
      ],
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/last_model_no.h5'\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])"
      ],
      "metadata": {
        "id": "Pzdjs0WbvDB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8XhlbWn--8Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature map for first hidden layer\n",
        "y_train_pred = model2.predict(X_train_fm_ov)\n",
        "y_val_pred = model2.predict(X_val_fm)"
      ],
      "metadata": {
        "id": "IW-_U6vFpIci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ],
      "metadata": {
        "id": "OLop0YK-ZK40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QdyCbloQyWTC",
        "outputId": "fc7dc3aa-1e48-41a5-e6a9-cfaada1de817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          AKIEC       BCC       BKL        DF       MEL        NV      VASC  \\\n",
              "0  4.000000e+00  4.000000  4.000000  4.000000  4.000000  4.000000  4.000000   \n",
              "1  1.102238e-04  0.000009  0.014549  0.000010  0.010376  0.974909  0.000037   \n",
              "2  1.202458e-01  0.862706  0.007830  0.002828  0.005415  0.000890  0.000086   \n",
              "3  6.322284e-07  0.000003  0.197923  0.000023  0.002732  0.787744  0.011574   \n",
              "4  6.019616e-05  0.000008  0.001310  0.000063  0.017424  0.981026  0.000109   \n",
              "\n",
              "   0.0  0.025  0.05  0.075  0.1  0.125  0.15  0.175  0.2  0.225  0.25  \n",
              "0    1      1     1      1    1      1     1      1    1      1     1  \n",
              "1    1      0     0      0    0      0     0      0    0      0     0  \n",
              "2    1      0     0      0    0      0     0      0    0      0     0  \n",
              "3    1      0     0      0    0      0     0      0    0      0     0  \n",
              "4    1      0     0      0    0      0     0      0    0      0     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ab50a96-cee5-4ce2-9ff3-156784a915d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BCC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>VASC</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.025</th>\n",
              "      <th>0.05</th>\n",
              "      <th>0.075</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.125</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.175</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.225</th>\n",
              "      <th>0.25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.102238e-04</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.014549</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.010376</td>\n",
              "      <td>0.974909</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.202458e-01</td>\n",
              "      <td>0.862706</td>\n",
              "      <td>0.007830</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.322284e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.197923</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>0.787744</td>\n",
              "      <td>0.011574</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.019616e-05</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.017424</td>\n",
              "      <td>0.981026</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ab50a96-cee5-4ce2-9ff3-156784a915d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ab50a96-cee5-4ce2-9ff3-156784a915d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ab50a96-cee5-4ce2-9ff3-156784a915d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "W31LSzov1tCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "eeb4dddd-368e-4c6c-fc24-83edb28c47e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.075\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3U2tkFebL_VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3480a8d2-66c8-405a-f551-8fc59bd3c462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6528497409326425\n",
            "Sensitivity:  1.0\n",
            "Specificity:  0.6104651162790697\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LOVl6dWlTDLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfe2ac3-ad76-423c-d8fb-5140e3184eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5906735751295337\n",
            "Balanced accuracy:  0.6207660225952909\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mqvYutTKRhR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481f1bb2-7b6b-4e51-baef-036bd0f9e864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  0  1  0  4  0  0]\n",
            " [ 3  7  0  2  3  0  0]\n",
            " [ 0  1  5  1 15  0  0]\n",
            " [ 0  0  0  1  0  0  0]\n",
            " [ 0  0  0  0 21  0  0]\n",
            " [ 0  1  3  0 44 75  0]\n",
            " [ 0  0  0  0  1  0  2]]\n"
          ]
        }
      ],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gVtvW3YeaLlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "0160a847-45d4-430c-92fc-56a6de0e6c20"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "2aa2c11c-6d22-4837-ce17-ec22f5ddda42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = model.predict(X_test)"
      ],
      "metadata": {
        "id": "KeDTXdaMLmyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "5edbf106-6a66-4e09-d1d4-7d4a11fa144d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_Oversampling_featuremapsbeforelastblock_resnet_trainablelastblock.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "result: 0.656"
      ],
      "metadata": {
        "id": "P0MghVs0tsGw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2IncA-_o_n5w",
        "outputId": "6db08704-addd-42d9-9371-4d805a2db101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0, 0, 'DF'),\n",
              " Text(0, 0, 'VASC'),\n",
              " Text(0, 0, 'AKIEC'),\n",
              " Text(0, 0, 'BCC'),\n",
              " Text(0, 0, 'BKL'),\n",
              " Text(0, 0, 'MEL'),\n",
              " Text(0, 0, 'NV')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "#labels = sorted(df_train['Labels'].unique())\n",
        "#for label in range(7):\n",
        "#    plot_images_per_label(y_train, 3, (12,9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6qneWL_Bs2U",
        "outputId": "cc7899de-f169-4850-dbe2-44ffb5a994d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:  (11261, 224, 224, 3)\n",
            "Remaining Data:  (2816, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3K908bbiYwbS",
        "RcRGeofw-8tK",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}